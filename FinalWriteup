Writeup For 
------------

###Working with Outwit Hub

When I first heard of Outwit Hub i thought it was just a system to look at a webpages source, something any webbrowser can do. But after using it for a bit it seems like it has some powerful tools.

***Essentially...***

It looks for tag's and takes the data inside them, and produces a 2_by_N spreadsheet with a tag refering to data. It's a great too for when the data is easy to access but tedious to collect. 

###Working with BASH Scripts as a Data Mining Tool 

This is more my style, using BASH commands to collect data. Reading through the command it is relitively simple. It downloads the JSON based on each key in the search. Its not as clean as the HTML scraper as it does not store it as a .CSV it is stored in a single document seperated by JSON objects. I worked with Wget in my studies as a computer scientist. Normally it is used as a simple application downloader. What i saw here was something i didnet know Wget could do. Downloading entire websites or sections is a very powerful tool.

###Voyant and R

Voyant is the coolest tool ive found in this course and in my project it was incredibly useful. The best use i found was the removal of stop words and the Keywords in context tool. The keywords in context is very useful when topic modeling does not work. What I found very useful was to get the KWIC and reload them as the courpus then do a word cloud on them. The results are very showing.

With R I was hesitant, It's a very intimidating system. I compare it to MATLAB for words. 